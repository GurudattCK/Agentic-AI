{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJdEc5U1fZzL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WADfrUNwfjwB"
      },
      "source": [
        "# **Understanding Agentic RAG: Building Intelligent Document Assistants with ChromaDB(Vectore DB) & LangChain(Framework)**\n",
        "\n",
        "### **What You'll Achieve** \ud83c\udfaf\n",
        "\n",
        "By the end of this lab, you'll gain a deep understanding of **Agentic RAG (Retrieval-Augmented Generation)** and how it revolutionizes the way we interact with documents. Here's what you'll learn:\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Storing Documents Intelligently Using Vector Embeddings** \ud83d\uddc2\ufe0f\n",
        "- **What**: Learn how to convert documents into numerical representations (vector embeddings) that capture their meaning.\n",
        "- **How**: Use **ChromaDB**, a vector database, to store and organize these embeddings efficiently.\n",
        "- **Why**: This allows the system to understand and retrieve information based on semantic meaning, not just keywords.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Retrieving Information with Semantic Understanding** \ud83d\udd0d\n",
        "- **What**: Discover how to fetch relevant information from a large document collection using semantic search.\n",
        "- **How**: Leverage **LangChain** to query ChromaDB and retrieve the most contextually relevant chunks.\n",
        "- **Why**: This ensures that the system understands the intent behind your questions, not just the literal words.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Generating Context-Aware Answers Using Agentic Decision-Making** \ud83e\udd16\n",
        "- **What**: Explore how **Agentic RAG** makes smart decisions about how to answer questions.\n",
        "- **How**: Implement a decision-making agent that evaluates the confidence of retrieved information and chooses the best response strategy.\n",
        "- **Why**: This allows the system to provide accurate and contextually appropriate answers, even when the information is incomplete or ambiguous.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Optimizing Responses Through Knowledge Graph Enhancements** \ud83e\udde0\n",
        "- **What**: Learn how to enhance answers by connecting related concepts using a knowledge graph.\n",
        "- **How**: Build a knowledge graph that maps terms and relationships (e.g., \"Master Agreement\" \u2192 \"Contract\") to improve understanding.\n",
        "- **Why**: This enables the system to provide more comprehensive and insightful answers by leveraging contextual connections.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Let's Get Started!** \ud83d\ude80\n",
        "Ready to dive in? Follow the steps in the lab to see how these concepts come to life in code. By the end, you'll not only understand **Agentic RAG** but also know how to implement it in real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p1YBrA6HRnoG"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install required libraries\n",
        "! pip install chromadb langchain pypdf2 sentence-transformers pyboxen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mURYH1rugGdk"
      },
      "source": [
        "### \ud83c\udf10 **About LangChain (In Simple Terms)**\n",
        "LangChain is a framework that helps developers **connect AI models with external data sources** like databases or APIs. In this project, we use LangChain to:\n",
        "- Embed text for efficient search.\n",
        "- Retrieve relevant information from the database.\n",
        "- Generate answers using OpenAI\u2019s model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WbLlwKiMmAQE"
      },
      "outputs": [],
      "source": [
        "# Step 1.1 Intsall this package as well\n",
        "! pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNfSJPCdnM3y"
      },
      "source": [
        "# Step 3: Setting Up the Lab \ud83e\uddea\n",
        "\n",
        "---\n",
        "## Import necessary modules\n",
        "Before we start, we need to install the necessary tools. These packages are like the ingredients for our recipe \u2013 without them, the lab won't work!\n",
        "\n",
        "# \ud83d\udccc Explanation of Imported Modules  \n",
        "\n",
        "## \ud83d\udd39 UI Components  \n",
        "- **`ipywidgets`** \u2192 Provides interactive widgets like buttons, text boxes, and dropdowns.  \n",
        "- **`IPython.display`** \u2192 Used to display widgets, clear output, and update UI dynamically.  \n",
        "\n",
        "## \ud83d\udd39 Data Processing & Utility  \n",
        "- **`random`** \u2192 Generates random numbers, useful for testing and sampling.  \n",
        "- **`typing (List, Dict)`** \u2192 Provides type hints for better code readability and debugging.  \n",
        "- **`io.BytesIO`** \u2192 Handles in-memory file operations without saving to disk.  \n",
        "- **`os`** \u2192 Interacts with the operating system (e.g., file paths, environment variables).  \n",
        "\n",
        "## \ud83d\udd39 LangChain Components  \n",
        "- **`langchain.vectorstores.Chroma`** \u2192 Stores and retrieves document embeddings efficiently.  \n",
        "- **`langchain.embeddings.HuggingFaceEmbeddings`** \u2192 Uses Hugging Face models for text embeddings.  \n",
        "- **`langchain.text_splitter.RecursiveCharacterTextSplitter`** \u2192 Splits text into manageable chunks for processing.  \n",
        "- **`langchain.llms.OpenAI`** \u2192 Connects to OpenAI\u2019s LLM for generating responses.  \n",
        "- **`langchain.agents.initialize_agent`** \u2192 Creates an AI agent with tools for querying documents.  \n",
        "- **`langchain.tools.Tool`** \u2192 Defines custom tools for AI agents.  \n",
        "- **`langchain.tools.StructuredTool`** \u2192 Provides structured tools for better AI responses.  \n",
        "- **`langchain.prompts.ChatPromptTemplate`** \u2192 Creates structured prompts for AI interactions.  \n",
        "- **`langchain.schema.runnable.RunnablePassthrough`** \u2192 Allows passing data through AI models without modification.  \n",
        "\n",
        "## \ud83d\udd39 PDF Handling  \n",
        "- **`PyPDF2.PdfReader`** \u2192 Reads and extracts text from PDF documents.  \n",
        "\n",
        "## \ud83d\udd39 Database & Storage  \n",
        "- **`chromadb`** \u2192 A fast and scalable vector database for storing and retrieving embeddings.  \n",
        "\n",
        "## \ud83d\udd39 UI Styling  \n",
        "- **`pyboxen.boxen`** \u2192 Formats text in visually appealing boxed outputs.  \n",
        "\n",
        "## \ud83d\udd39 Data Validation  \n",
        "- **`pydantic.BaseModel, Field`** \u2192 Ensures structured and validated data inputs.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt7L9rR0UrbR"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import necessary modules\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import random\n",
        "from typing import List, Dict\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from pydantic import BaseModel, Field\n",
        "from PyPDF2 import PdfReader\n",
        "import chromadb\n",
        "from pyboxen import boxen\n",
        "import os\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypvDMdbggis"
      },
      "source": [
        "### \ud83d\udccc **Step 3: Initializing Components - Setting Up AI-Powered Document Processing: Embeddings, Vector Storage, and LLM Integration**\n",
        "```python\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "llm = OpenAI(temperature=0)\n",
        "```\n",
        "- **Embeddings:** We use `HuggingFaceEmbeddings` to convert text into numerical format.\n",
        "- **ChromaDB Client:** Creates a database at `./chroma_db` to store text embeddings.\n",
        "- **OpenAI API:** We set the API key to access OpenAI\u2019s language model.\n",
        "[Generate Your OpenAI API Key](https://github.com/initmahesh/MLAI-community-labs/tree/main/Class-Labs/Lab-0(Pre-requisites))\n",
        "\n",
        "- **LLM Initialization:** We set the temperature to `0` for more deterministic responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-P9jwcSyUvdv"
      },
      "outputs": [],
      "source": [
        "# Step 3: Initialize components\n",
        "# Initialize embedding model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize ChromaDB client\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# Initialize LLM (Replace with your API key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld1FlCazgsgP"
      },
      "source": [
        "# \ud83d\udccc Step 4: Upload & Process a PDF Document  \n",
        "\n",
        "This step allows users to upload a PDF file, extract its text, split it into smaller chunks, and store it in a vector database for AI processing.  \n",
        "\n",
        "## \ud83d\udd39 How It Works  \n",
        "1. **File Upload Widget**  \n",
        "   - A button appears that lets you upload a **PDF file**.  \n",
        "   - The system only accepts **one file at a time**.  \n",
        "\n",
        "2. **Processing the File**  \n",
        "   - When you click the **\"Process File\"** button:  \n",
        "     - The system checks if a file is uploaded.  \n",
        "     - If no file is found, it shows a message: **\"No file uploaded!\"**  \n",
        "     - If a file is uploaded, the system reads the PDF and extracts its text.  \n",
        "     - The text is split into smaller **chunks** (for efficient processing).  \n",
        "     - Each chunk is assigned a **random confidence score**.  \n",
        "     - The data is stored in **ChromaDB**, a special AI-ready database.  \n",
        "\n",
        "3. **Success Message**  \n",
        "   - If everything works, you\u2019ll see a **green notification box**:  \n",
        "     ```\n",
        "     File processed with confidence scores!\n",
        "     ```  \n",
        "   - This means your file was successfully processed and stored.  \n",
        "\n",
        "## \ud83d\udd39 Steps to Use  \n",
        "\u2705 **Step 1** \u2192 Click on **\"Upload Document\"** and select a PDF file.  \n",
        "\u2705 **Step 2** \u2192 Click **\"Process File\"** to analyze and store it.  \n",
        "\u2705 **Step 3** \u2192 Wait for the **success message** confirming the file is processed.  \n",
        "\n",
        "**\u2705 NOTE** : [\ud83d\udcc4 **Reference Document You Can Use**](https://drive.google.com/file/d/1WWa_TgI49HIAGFuXTNvMLtkFBU6ZduHq/view?usp=sharing)\n",
        "\n",
        "This setup makes it easy to upload and process PDFs with AI-powered storage. \ud83d\ude80  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPaM1w24U1tF"
      },
      "outputs": [],
      "source": [
        "# Step 4: File upload widget with value storage\n",
        "import random\n",
        "uploader = widgets.FileUpload(accept='.pdf', multiple=False)\n",
        "process_btn = widgets.Button(description=\"Process File\")\n",
        "process_output = widgets.Output()\n",
        "\n",
        "def process_file(b):\n",
        "    with process_output:\n",
        "        clear_output()\n",
        "        if not uploader.value:\n",
        "            print(\"No file uploaded!\")\n",
        "            return\n",
        "\n",
        "        for filename, file_info in uploader.value.items():\n",
        "            pdf = PdfReader(BytesIO(file_info['content']))\n",
        "            break\n",
        "\n",
        "        text = \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000, chunk_overlap=100\n",
        "        )\n",
        "        chunks = text_splitter.split_text(text)\n",
        "        metadatas = [{\"value\": random.uniform(0, 1)} for _ in chunks]\n",
        "\n",
        "        Chroma.from_texts(\n",
        "            chunks, embeddings,\n",
        "            client=chroma_client,\n",
        "            collection_name=\"doc_collection\",\n",
        "            metadatas=metadatas\n",
        "        )\n",
        "        print(boxen(\"File processed with confidence scores!\", title=\"Success\", color=\"green\"))\n",
        "\n",
        "display(uploader, process_btn, process_output)\n",
        "process_btn.on_click(process_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsnCbBlhg-sv"
      },
      "source": [
        "# \ud83d\udcdd Step 5: Enhanced Query Processing with an Agent  \n",
        "\n",
        "This step enhances **query processing** by implementing an **AI agent** that decides how to answer user queries based on **confidence scores**. It retrieves relevant document chunks and determines whether the response should be **directly generated** or **refined using a knowledge graph** for better accuracy.  \n",
        "\n",
        "---\n",
        "## \ud83d\udd39 Overview of the Query Processing Flow  \n",
        "\n",
        "### 1\ufe0f\u20e3 **User Query Retrieval**  \n",
        "- The user submits a **query**.\n",
        "- The system **retrieves relevant document chunks** using ChromaDB.\n",
        "- Each retrieved chunk has an **associated confidence score**.\n",
        "\n",
        "### 2\ufe0f\u20e3 **Confidence Score Evaluation**  \n",
        "- If the confidence score is **high (\u2265 0.5)** \u2192 Use a **direct answer** approach.\n",
        "- If the confidence score is **low (< 0.3)** \u2192 Use a **knowledge-enhanced answer**.\n",
        "\n",
        "### 3\ufe0f\u20e3 **Knowledge Graph Enhancement** (for low-confidence cases)  \n",
        "- Some terms in the query are mapped to **more meaningful alternatives** using a **knowledge graph**.\n",
        "- The query is **rewritten** with these enhancements.\n",
        "- A new document search is performed using the improved query.\n",
        "\n",
        "### 4\ufe0f\u20e3 **Generating the Final Answer**  \n",
        "- The system **chooses the best response strategy** using an autonomous agent.\n",
        "- The **final answer is generated** based on the refined context and confidence evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udd0d **Understanding Confidence Scores**  \n",
        "\n",
        "A **confidence score** is a measure of **how relevant** a retrieved document chunk is to the user's query.  \n",
        "- **Higher confidence (\u2265 0.5)** \u2192 The retrieved text is **relevant and reliable**.  \n",
        "- **Lower confidence (< 0.3)** \u2192 The retrieved text **may not be relevant or sufficient**.  \n",
        "\n",
        "### \ud83d\udccc **How is the Confidence Score Used?**  \n",
        "- If the retrieved document chunk has a **high confidence score**, the system can **directly answer the query**.  \n",
        "- If the retrieved document chunk has a **low confidence score**, the AI **enhances the query** using a **knowledge graph** and **retrieves better chunks**.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83e\udd16 **Role of the AI Agent**  \n",
        "\n",
        "The **AI Agent** acts as a **decision-maker** that chooses the **best answering approach** based on **confidence scores**.  \n",
        "\n",
        "### \ud83d\udd39 **How the Agent Works**\n",
        "1. **User submits a query**.\n",
        "2. **Document chunks are retrieved** from the database.\n",
        "3. **Each chunk has an associated confidence score**.\n",
        "4. The AI agent **analyzes the confidence scores** and chooses:\n",
        "   - \u2705 **Direct Answer** \u2192 If confidence is **high (\u2265 0.5)**.\n",
        "   - \ud83d\udd04 **Enhanced Answer** \u2192 If confidence is **low (< 0.3)**, it **rewrites the query** and **retrieves better chunks**.\n",
        "5. The chosen **answering tool is executed**, and the **final response** is provided.  \n",
        "\n",
        "---\n",
        "\n",
        "# What is Knowledge Graph\n",
        "\n",
        "A **Knowledge Graph** is a structured representation of information that connects data points using relationships. It organizes and links concepts, entities, and facts in a way that allows machines (like AI) to understand and reason about the data.\n",
        "\n",
        "## Key Components of a Knowledge Graph\n",
        "1. **Entities (Nodes)** \u2013 Objects or concepts (e.g., a company, a contract, a product).\n",
        "2. **Relationships (Edges)** \u2013 Connections between entities (e.g., \"Customer **has** a Master Agreement\").\n",
        "3. **Attributes (Properties)** \u2013 Details about entities (e.g., \"Contract Start Date: Jan 2024\").\n",
        "\n",
        "## Example of a Simple Knowledge Graph\n",
        "\n",
        "### \ud83d\udccc Entities:\n",
        "- **Customer**: ABC Corp\n",
        "- **Master Agreement**: Contract\n",
        "- **Service Order**: Specific service agreement\n",
        "\n",
        "### \ud83d\udccc Relationships:\n",
        "- `ABC Corp \u2192 has \u2192 Master Agreement`\n",
        "- `Master Agreement \u2192 includes \u2192 Service Order`\n",
        "\n",
        "## Why Use a Knowledge Graph?\n",
        "- \ud83d\ude80 Helps AI understand context better\n",
        "- \ud83d\udd0d Improves search and query responses\n",
        "- \ud83d\udd17 Connects scattered information for better decision-making\n",
        "\n",
        "# NOTE\n",
        "# We are using a dummy knowledge graph with respect to three terms:\n",
        "\n",
        "- **Customer**:\n",
        "- **Master Agreement**:\n",
        "- **Service Order**:\n",
        "\n",
        "# If you are using a query different from it, then you have to provide your context to the knowledge graph as well.\n",
        "---\n",
        "\n",
        "# \ud83c\udfaf **Final Outcome**\n",
        "- If the retrieved document is **relevant**, the AI answers immediately.  \n",
        "- If the information is **uncertain**, the AI **optimizes** the search before answering.  \n",
        "- The AI agent makes **independent decisions** for the best response. \ud83d\ude80  \n",
        "\n",
        "This **smart decision-making** process makes the AI **more intelligent and reliable** for answering document-based queries. \ud83d\udcd6\u2728\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfeLdybzU5VW"
      },
      "outputs": [],
      "source": [
        "# Step 5: Enhanced query processing with autonomous agent\n",
        "class QueryInput(BaseModel):\n",
        "    query: str = Field(description=\"User's original question\")\n",
        "    chunks: List[Dict] = Field(description=\"Retrieved document chunks with confidence scores\")\n",
        "\n",
        "def retrieve_chunks(query: str) -> List[Dict]:\n",
        "    collection = chroma_client.get_collection(\"doc_collection\")\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=1,\n",
        "        include=['documents', 'metadatas']\n",
        "    )\n",
        "\n",
        "    # Ensure metadata is returned and handle cases where it's missing\n",
        "    documents = results['documents'][0]\n",
        "    metadatas = results.get('metadatas', [[{}] * len(documents)])[0]  # Default to empty dicts if metadata is missing\n",
        "\n",
        "    # Simulate low-confidence chunks for testing\n",
        "    simulated_chunks = [\n",
        "        {\"text\": doc, \"value\": random.uniform(0.2, 0.4)}  # Simulate low confidence scores (0.2 to 0.4)\n",
        "        for doc, meta in zip(documents, metadatas)\n",
        "    ]\n",
        "\n",
        "    return simulated_chunks\n",
        "\n",
        "def knowledge_graph(query: str) -> str:\n",
        "    # Enhanced knowledge graph mappings\n",
        "    kg_mappings = {\n",
        "        \"customer\": \"Company Name Referenced in Master Agreement Only\",\n",
        "        \"Master Agreement\": \"Contract\",\n",
        "        \"Service Order\": \"Service Agreement\",\n",
        "        \"name of the Customer\": \"Company Name Referenced in Master Agreement Only\",\n",
        "        # Add case variations or use case-insensitive comparison\n",
        "        \"Name Of the Customer\": \"Company Name Referenced in Master Agreement Only\"\n",
        "    }\n",
        "\n",
        "    # Alternatively, use case-insensitive replacement:\n",
        "    enhanced_query = query\n",
        "    for term, replacement in kg_mappings.items():\n",
        "        pattern = re.compile(re.escape(term), re.IGNORECASE)\n",
        "        enhanced_query = pattern.sub(replacement, enhanced_query)\n",
        "\n",
        "    return enhanced_query\n",
        "\n",
        "def base_answer(input: QueryInput) -> str:\n",
        "    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in input.chunks])\n",
        "    prompt = f\"Answer: {input.query}\\nContext:\\n{context}\"\n",
        "    answer = llm(prompt)\n",
        "    return f\"Answer: {answer}\"\n",
        "\n",
        "def enhanced_answer(input: QueryInput) -> str:\n",
        "    enhanced_query = knowledge_graph(input.query)\n",
        "    enhanced_chunks = retrieve_chunks(enhanced_query)\n",
        "    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in enhanced_chunks])\n",
        "    prompt = f\"Answer: {enhanced_query}\\nContext:\\n{context}\"\n",
        "    answer = llm(prompt)\n",
        "    return f\"Optimized Answer: {answer}\"\n",
        "\n",
        "\n",
        "# Define Tools\n",
        "tools = [\n",
        "    StructuredTool.from_function(\n",
        "        name=\"DirectAnswer\",\n",
        "        description=\"Use this when the retrieved chunks have high confidence scores (>= 0.5) and sufficient context to directly answer the query.\",\n",
        "        func=base_answer\n",
        "    ),\n",
        "    StructuredTool.from_function(\n",
        "        name=\"EnhancedAnswer\",\n",
        "        description=\"Use this when the retrieved chunks have low confidence scores (< 0.3) or insufficient context, and the query needs to be enhanced using a knowledge graph.\",\n",
        "        func=enhanced_answer\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize the agent with a custom prompt\n",
        "agent_prompt = \"\"\"You are an intelligent assistant that decides how to answer user queries based on the context and confidence scores of retrieved document chunks.\n",
        "\n",
        "Here are the tools available to you:\n",
        "1. DirectAnswer: Use this when the retrieved chunks have high confidence scores (>= 0.5) and sufficient context to directly answer the query.\n",
        "2. EnhancedAnswer: Use this when the retrieved chunks have low confidence scores (< 0.3) or insufficient context, and the query needs to be enhanced using a knowledge graph.\n",
        "\n",
        "Your task is to analyze the query, retrieved chunks, and their confidence scores, and decide which tool to use. Provide a reason for your decision.\n",
        "\n",
        "Query: {query}\n",
        "Retrieved Chunks: {chunks}\n",
        "\n",
        "Decision: Which tool should be used? Respond in the following format:\n",
        "Tool: [DirectAnswer or EnhancedAnswer]\n",
        "Reason: [Your reasoning]\"\"\"\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=\"structured-chat-zero-shot-react-description\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aaAiW68hiqJ"
      },
      "source": [
        "# \ud83d\udcdd **Step 6: Query Interface with Autonomous Decision-Making**  \n",
        "\n",
        "This step introduces an **interactive query interface** that allows users to input their questions.  \n",
        "The AI agent **analyzes** the query, **retrieves relevant document chunks**, and **decides how to answer**  \n",
        "based on confidence scores. The decision-making is fully **autonomous**, ensuring **optimized responses**.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83c\udfaf **How the Query Interface Works**  \n",
        "\n",
        "### \ud83d\udd39 **User Input & Query Submission**  \n",
        "- You have to enters their query in the input field (`query_input`).\n",
        "- Clicking the \"Submit\" button (`submit_btn`) triggers the `handle_query` function.\n",
        "\n",
        "# \ud83d\udd0d Step-by-Step Query Processing Flow\n",
        "**1\ufe0f\u20e3 Step 1: Query Asked**\n",
        "- The user inputs a query.\n",
        "- The query is displayed in a notification box for reference.\n",
        "\n",
        "**2\ufe0f\u20e3 Step 2: Retrieve Relevant Chunks**\n",
        "- The query is searched in the document database (ChromaDB).\n",
        "- The most relevant text chunks are retrieved, along with their confidence scores.\n",
        "- Retrieved chunks are displayed in a green notification box.\n",
        "\n",
        "**3\ufe0f\u20e3 Step 3: Generate an Initial (Poor) Answer**\n",
        "- The system tries to generate an answer from the retrieved chunks.\n",
        "- This is an unoptimized response that might be incorrect due to low confidence scores.\n",
        "- The poor answer is displayed in a red notification box.\n",
        "\n",
        "**4\ufe0f\u20e3 Step 4: AI Agent Decision**\n",
        "- The AI agent analyzes the retrieved chunks and confidence scores.\n",
        "- It decides whether to:\n",
        "  - Use the DirectAnswer tool (if confidence scores are high).\n",
        "  - Use the EnhancedAnswer tool (if confidence scores are low).\n",
        "- The agent's decision is displayed in a magenta notification box.\n",
        "\n",
        "**5\ufe0f\u20e3 Step 5: Generate the Final Answer**\n",
        "\n",
        "\u2705 If the agent chooses \"DirectAnswer\"\n",
        "- The initial answer is used without modifications.\n",
        "\n",
        "\u2705 If the agent chooses \"EnhancedAnswer\"\n",
        "- The query is refined by agnet using a Knowledge Graph.\n",
        "-A new set of relevant document chunks is retrieved.\n",
        "- A more optimized answer is generated.\n",
        "\n",
        "# \ud83c\udfc1 How to Use the Query Interface?\n",
        "1\ufe0f\u20e3 Enter your question in the input box.\n",
        "\n",
        "```text\n",
        "What is the name of the Customer ?\n",
        "```\n",
        "\n",
        "2\ufe0f\u20e3 Click \"Submit\" to process the query.\n",
        "\n",
        "3\ufe0f\u20e3 The system will retrieve relevant document chunks and evaluate confidence scores.\n",
        "\n",
        "4\ufe0f\u20e3 The AI agent decides whether to give a direct answer or enhance the query using a Knowledge Graph.\n",
        "\n",
        "5\ufe0f\u20e3 The final answer is displayed, either as a Direct Answer or an Optimized Answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "887573021d944d879c5170b744660343",
            "c1bc83a2ee6844cab4204d5d5f178a7d",
            "9d33fae4591c4de39c0be234dc383f01",
            "62e08ae9e43d4b7698a12e340a8a8dbc",
            "e72b18e8a47440279e7672658053bab6",
            "8cca3ce104434b138766cbc0ed5fe0b8",
            "4c374ab724574ea6931e544ce095678a",
            "81af15beff0a4fd6980f3b01893bcf51"
          ]
        },
        "collapsed": true,
        "id": "JORFQMonVaFK",
        "outputId": "9f292b80-4769-4ddd-e390-07e1fb450271"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "887573021d944d879c5170b744660343",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='', placeholder='Enter your query')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62e08ae9e43d4b7698a12e340a8a8dbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c374ab724574ea6931e544ce095678a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import re\n",
        "# Step 6: Query interface with autonomous decision-making\n",
        "query_input = widgets.Text(placeholder=\"Enter your query\")\n",
        "submit_btn = widgets.Button(description=\"Submit\")\n",
        "query_output = widgets.Output()\n",
        "\n",
        "def handle_query(b):\n",
        "    with query_output:\n",
        "        clear_output()\n",
        "        query = query_input.value\n",
        "\n",
        "        # Step 1: Query Asked\n",
        "        print(boxen(f\"QUERY ASKED:\\n{query}\", title=\"Step 1: Query Asked\", color=\"blue\"))\n",
        "\n",
        "        # Step 2: Retrieve Chunks\n",
        "        chunks = retrieve_chunks(query)\n",
        "        print(boxen(\n",
        "            f\"RETRIEVED CHUNKS:\\n\" +\n",
        "            \"\\n\".join([f\"Chunk {i+1}: {chunk['text']}\"\n",
        "                       for i, chunk in enumerate(chunks)]),\n",
        "            title=\"Step 2: Retrieved Chunks\", color=\"green\"\n",
        "        ))\n",
        "\n",
        "        # Step 3: Generate and Display Poor Answer\n",
        "        poor_answer = base_answer(QueryInput(query=query, chunks=chunks))\n",
        "        print(boxen(\n",
        "            f\"POOR ANSWER (Initial Attempt):\\n{poor_answer}\",\n",
        "            title=\"Step 3: Poor Answer\", color=\"red\"\n",
        "        ))\n",
        "\n",
        "        # Step 4: Let the Agent Decide Which Tool to Use\n",
        "        decision_output = llm(agent_prompt.format(query=query, chunks=chunks))\n",
        "        decision = decision_output.split(\"Tool: \")[1].split(\"\\n\")[0].strip()  # Extract tool\n",
        "        reason = decision_output.split(\"Reason: \")[1].strip()  # Extract reason\n",
        "        print(boxen(\n",
        "            f\"AGENT DECISION:\\nTool: KNOWLEDGE GRAPH\\nReason: {reason}\",\n",
        "            title=\"Step 4: Agent Decision\", color=\"magenta\"\n",
        "        ))\n",
        "\n",
        "        # Step 5: Execute the Chosen Tool\n",
        "        if \"DirectAnswer\" in decision:\n",
        "            response = base_answer(QueryInput(query=query, chunks=chunks))\n",
        "            print(boxen(\n",
        "                f\"DIRECT ANSWER:\\n{response}\",\n",
        "                title=\"Step 5: Direct Answer\", color=\"yellow\"\n",
        "            ))\n",
        "        elif \"EnhancedAnswer\" in decision:\n",
        "            print(boxen(\n",
        "                \"USING KNOWLEDGE GRAPH TO ENHANCE QUERY...\",\n",
        "                title=\"Step 5: Knowledge Graph Enhancement\", color=\"cyan\"\n",
        "            ))\n",
        "            enhanced_query = knowledge_graph(query)\n",
        "            print(boxen(\n",
        "                f\"ENHANCED QUERY:\\n{enhanced_query}\",\n",
        "                title=\"Step 5: Enhanced Query\", color=\"cyan\"\n",
        "            ))\n",
        "            enhanced_chunks = retrieve_chunks(enhanced_query)\n",
        "            response = enhanced_answer(QueryInput(query=enhanced_query, chunks=enhanced_chunks))\n",
        "            print(boxen(\n",
        "                f\"FINAL OPTIMIZED ANSWER:\\n{response}\",\n",
        "                title=\"Step 5: Final Optimized Answer\", color=\"green\"\n",
        "            ))\n",
        "        else:\n",
        "            print(boxen(\n",
        "                \"Unable to determine the appropriate tool. Using default answer.\",\n",
        "                title=\"Step 5: Default Answer\", color=\"red\"\n",
        "            ))\n",
        "\n",
        "\n",
        "display(query_input, submit_btn, query_output)\n",
        "submit_btn.on_click(handle_query)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}