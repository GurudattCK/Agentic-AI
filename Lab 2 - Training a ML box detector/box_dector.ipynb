{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ef6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, time\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import BlobServiceClient, PublicAccess, BlobType, generate_blob_sas, BlobSasPermissions\n",
    "from azure.storage.queue import QueueServiceClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import CustomVisionErrorException\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from twilio.rest import Client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb5fb7a",
   "metadata": {},
   "source": [
    "Setting up environment variables and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003956ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'STORAGE_ACCOUNT_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m ENDPOINT \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://southcentralus.api.cognitive.microsoft.com\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m ACCOUNT_NAME \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mACCOUNT_NAME\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m STORAGE_ACCOUNT_KEY \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mSTORAGE_ACCOUNT_KEY\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     15\u001b[0m prediction_credentials \u001b[39m=\u001b[39m ApiKeyCredentials(in_headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mPrediction-key\u001b[39m\u001b[39m\"\u001b[39m: PREDICTION_KEY})\n\u001b[0;32m     16\u001b[0m predictor \u001b[39m=\u001b[39m CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
      "File \u001b[1;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'STORAGE_ACCOUNT_KEY'"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "CONNECTION_STRING = os.getenv('CONNECTION_STRING').strip()\n",
    "SOURCE = os.getenv('SOURCE')\n",
    "TIME_DELAY = int(os.getenv('TIME_DELAY'))\n",
    "MANUAL_MODE = int(os.getenv('MANUAL_MODE'))\n",
    "ACCOUNT_SID = os.environ['TWILIO_ACCOUNT_SID']\n",
    "AUTH_TOKEN = os.environ['TWILIO_AUTH_TOKEN']\n",
    "PHONE_NUMBER = os.environ['TWILIO_PHONE_NUMBER']\n",
    "PREDICTION_KEY = os.environ['PREDICTION_KEY']\n",
    "TRAINING_KEY = os.environ['TRAINING_KEY']\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "ENDPOINT = \"https://southcentralus.api.cognitive.microsoft.com\"\n",
    "ACCOUNT_NAME = os.environ['ACCOUNT_NAME']\n",
    "STORAGE_ACCOUNT_KEY = os.environ['STORAGE_ACCOUNT_KEY']\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
    "\n",
    "\n",
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": TRAINING_KEY})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, training_credentials)\n",
    "\n",
    "client = Client(ACCOUNT_SID, AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10d38c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = CONNECTION_STRING\n",
    "source = SOURCE\n",
    "time_delay = TIME_DELAY\n",
    "manual_mode = MANUAL_MODE\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_name = None \n",
    "queue_service = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58177331",
   "metadata": {},
   "source": [
    "Creating a blob named 'fromcamera + current date time'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db0cfd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.storage.queue._queue_client.QueueClient at 0x1c3284d3bd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "container_name = 'fromcamera' + timestr\n",
    "blob_service_client.create_container(container_name)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "container_client.set_container_access_policy(signed_identifiers={}, public_access=PublicAccess.Container)\n",
    "queue_service = QueueServiceClient.from_connection_string(connection_string)\n",
    "queue_service.create_queue('fromcamera' + timestr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04969032",
   "metadata": {},
   "source": [
    "Inference function:\n",
    "- Gets the iteration name from custom vision.\n",
    "- Converts the image to bytes -> compresses -> and stores it in the memory.\n",
    "- Returns results recived from custom vision prefiction client that we created in [2] as 'predictor'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "873e154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference (frame):\n",
    "    # Get the project by project_id\n",
    "    try:\n",
    "        iterations = trainer.get_iterations(PROJECT_ID)\n",
    "        published_iteration = next(iteration for iteration in iterations if iteration.publish_name)\n",
    "        publish_iteration_name = published_iteration.publish_name\n",
    "    except StopIteration:\n",
    "        print(\"No published iteration found. Please publish an iteration in the Custom Vision portal.\")\n",
    "        exit(1)\n",
    "\n",
    "    image_jpg = cv2.imencode('.jpg',frame)[1].tobytes()\n",
    "    results = predictor.detect_image(PROJECT_ID, publish_iteration_name, image_jpg)\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88afa245",
   "metadata": {},
   "source": [
    "Upload frame function:\n",
    "- Takes the frame, iterator as 'i', and an optional suffix.\n",
    "- Stores the frame in memory 'image_jpg'.\n",
    "- Creats the blob name (adds the suffix at the end of the name if provided).\n",
    "- Creates a client to upload image to storage 'blob_client'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10f69942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_frame(frame, i, sufix=''):\n",
    "    print(\"frame capture function returned :: \" +  str(frame is not None) + \" storing to container :: \" + container_name)\n",
    "    image_jpg = cv2.imencode('.jpg',frame)[1].tobytes()\n",
    "    blob_name= 'image' + str(i) + sufix +'.jpg' if sufix else 'image' + str(i) +'.jpg'\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    blob_client.upload_blob(image_jpg, blob_type=BlobType.BlockBlob)\n",
    "    print(\"Total files stored :: \" + str(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395efb62",
   "metadata": {},
   "source": [
    "'save_to_filesystem' function saves the frame as jpg to local storage, and sets the frame name to current date time before storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c9ff1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_filesystem(frame):\n",
    "    #Stores frame as jpg locally\n",
    "    current_time = time.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    local_image_location = os.path.join(os.path.join(os.path.dirname('p='), \"test/\"))\n",
    "    cv2.imwrite(f\"{local_image_location}/{current_time}.jpg\", frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee7e11fd",
   "metadata": {},
   "source": [
    "Send SMS function sends a SMS alert to the user with the image url from storage:\n",
    "\n",
    "  Creates an empty list -> Gets all the blob from storage -> Checks if blob name has 'without' in it (as we are storing two images one with bounding box and one without bounding box) -> If 'without' not found in name, adds it to the list -> Sorts the blobs in the list by timestamp -> Generates a SAS token for the [0]th index image -> then creates a sas_url\n",
    "- body: 'string' that you want to send in the SMS.\n",
    "- from: phone number given by twilio.\n",
    "- to: recipents phone number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e69d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sms():\n",
    "    blob_list = []\n",
    "\n",
    "    for blob in container_client.list_blobs():\n",
    "        if 'without' in blob.name:\n",
    "            continue\n",
    "        blob_list.append(blob)  \n",
    "\n",
    "\n",
    "    sorted_list = sorted(blob_list, key=lambda e: e.creation_time, reverse=True)\n",
    "    sas_i = generate_blob_sas(\n",
    "        account_name= ACCOUNT_NAME,\n",
    "        container_name= container_name,\n",
    "        blob_name= sorted_list[0].name,\n",
    "        account_key= STORAGE_ACCOUNT_KEY,\n",
    "        permission= BlobSasPermissions(read=True),\n",
    "        expiry= datetime.utcnow() + timedelta(hours=8760)\n",
    "        )\n",
    "    sas_url = 'https://' + ACCOUNT_NAME +'.blob.core.windows.net/' + container_name + '/' + sorted_list[0].name + '?' + sas_i\n",
    "\n",
    "    message = client.messages.create(\n",
    "                        body=f'A Box is detected at you door! In case you are out you can view the image here: {sas_url}',\n",
    "                        from_= PHONE_NUMBER,\n",
    "                        to='+917303879964'\n",
    "                    )\n",
    "    print(sas_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf968062",
   "metadata": {},
   "source": [
    "1. Checking the source, if source is usb then stream will be captured from the webcam else a .mp4 video path can be provided.\n",
    "2. Checking the manual mode, if manual_mode = 0 frames will be sent automatically else frames can be sent manually from camera preview.\n",
    "3. Sending the frame to 'Infrance' function (created on [5]) which returns the predictions.\n",
    "4. Setting the Probability threshold as 80%.\n",
    "5. Looping through each prediction, and checking the probability, so that, all the predictions having a probability > 80% get skiped.\n",
    "6. Adding a bounding overley over detected object.\n",
    "7. Uploading the detected frame using upload_frame function (created on [6]).\n",
    "8. Saving the frame as jpg using save_to_filesystem function (created on [7]).\n",
    "9. Sending notification to user using send_sms function (created on [8]).\n",
    "10. Adding the time_delay to pause the code for the defined time_delay in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4adf16d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created stream\n",
      "frame capture function returned :: True storing to container :: fromcamera20230519-231034\n",
      "Total files stored :: 1\n",
      "\tBox: 100.00% bbox.left = 0.42, bbox.top = 0.46, bbox.width = 0.29, bbox.height = 0.29\n",
      "frame capture function returned :: True storing to container :: fromcamera20230519-231034\n",
      "Total files stored :: 1\n",
      "https://mlcohort.blob.core.windows.net/fromcamera20230519-231034/image1.jpg?se=2024-05-18T17%3A40%3A42Z&sp=r&sv=2022-11-02&sr=b&sig=9o2ODPoaExrXAgDsMbUBX6U0J8G5epyegVy2WClZ8G8%3D\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m     save_to_filesystem(frame)\n\u001b[0;32m     75\u001b[0m     send_sms()\n\u001b[1;32m---> 76\u001b[0m     time\u001b[39m.\u001b[39;49msleep(time_delay)\n\u001b[0;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo object detected\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if source is not None:\n",
    "    if source == 'usb':\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(source)\n",
    "else:\n",
    "    print(\"Please set the valuse of SOURCE variable in .env file\")\n",
    "    exit()\n",
    "\n",
    "ret = True\n",
    "i = 0\n",
    "print('Created stream')\n",
    "\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    if(frame is None):\n",
    "        print(\"Unable to capture frame from source :\" + source)\n",
    "        print(\"Please check correct SOURCE variable is set in .env file\")\n",
    "        break  \n",
    "\n",
    "    if(manual_mode == 1):\n",
    "        window_name = \"Press SPACE to capture or ESC to quit\"\n",
    "        cv2.namedWindow(window_name,cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(window_name, frame)\n",
    "              \n",
    "        k = cv2.waitKey(1)\n",
    "        if k%256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "                 \n",
    "        elif k%256 == 32:\n",
    "            # SPACE pressed\n",
    "            i+=1 \n",
    "            upload_frame(frame, i)\n",
    "    else:   \n",
    "        ret, frame = cap.read()\n",
    "        i+=1\n",
    "        results = inference(frame)\n",
    "        # Set the probability threshold (e.g., 0.8 for 80%)\n",
    "        probability_threshold = 0.8\n",
    "\n",
    "        # Display the results.\n",
    "        # The bounding box values are normalized, which means they are in the range of 0 to 1 relative to the image dimensions.\n",
    "        # To get the actual pixel coordinates, you can multiply these values by the width and height of the image, respectively.\n",
    "        for prediction in results.predictions:\n",
    "            if prediction.tag_name == 'Box':\n",
    "                if prediction.probability >= probability_threshold:\n",
    "                    url = f'https://mlcohort.blob.core.windows.net/{container_name}/image{i}.jpg'\n",
    "\n",
    "                    upload_frame(frame, i, '_without_overlay')\n",
    "\n",
    "                    #Storing bounding_box coordinates as x an y axis\n",
    "                    x = int(prediction.bounding_box.left * frame.shape[0])\n",
    "                    y = int(prediction.bounding_box.top * frame.shape[1])\n",
    "\n",
    "                    width = x + int(prediction.bounding_box.width * frame.shape[0])\n",
    "                    height = y + int(prediction.bounding_box.height * frame.shape[1])\n",
    "\n",
    "                    #Adding bounding_box to the frame\n",
    "                    frame = cv2.rectangle(frame, (x, y), (width, height), (0, 0, 255), 2)\n",
    "                    #Adding tag_name that we got from pridiction in the bounding_box\n",
    "                    frame = cv2.putText(frame, prediction.tag_name, (x + 5, y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 1, cv2.LINE_AA, False)\n",
    "                       \n",
    "                    #TODO\n",
    "                     #extract url from blob insted of hardcoding\n",
    "                     #check for pridiction tag_name\n",
    "                     #fix bounding box alignment\n",
    "                     #upload both bounding-box image and plane image\n",
    "                       \n",
    "                    print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability * 100, prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))\n",
    "                    upload_frame(frame, i)\n",
    "                    save_to_filesystem(frame)\n",
    "                    send_sms()\n",
    "                    time.sleep(time_delay)\n",
    "                else:\n",
    "                    print(\"No object detected\")\n",
    "                    time.sleep(time_delay)\n",
    "            else: \n",
    "                print('Something else was detected')              \n",
    "\n",
    "    cap.release()\n",
    "    print('Released stream')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
